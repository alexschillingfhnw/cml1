{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cml1 - Immobilienrechner\n",
    "# 2.2 Bestmögliches Regressionsmodell - kaggle-Contest\n",
    "\n",
    "Entwickle mit beliebigen Algorithmen das bestmögliche Modell im Sinne des Mean absolute percentage error (MAPE). Vergleiche dabei mindestens drei algorithmische Ansätze, wobei ein multiples lineares Modell Teil davon sein soll als Benchmark. Untersuche die ‘Variable Importance’ für dein bestes Modell.\n",
    "\n",
    "Abgabe\n",
    "\n",
    "Notebook und daraus erstellter Bericht (ohne Code) als pdf, welche die Entwicklung deines besten Modells, sowie der zwei weiteren Modelle dokumentiert, inklusive verwendeter Features, Preprocessing, Model Selection Prozess und Untersuchung der ‘Variable Importance’.\n",
    "\n",
    "Eingabe der Vorhersage des Preises für den Testdatensatz mit deinem bestmöglichen Modell auf kaggle."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# linear models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "\n",
    "# tree models\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# ensemble models\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor\n",
    "\n",
    "# xgb model\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# imputing\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "# pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold, RandomizedSearchCV\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "\n",
    "# save model\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten laden"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit die Predictions die korrekten IDs haben, müssen die rohe Kaggle-Daten geladen werden und die IDs extrahiert werden. Diese werden wir später wieder benötigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_kaggle = pd.read_csv('../../../data/test_data-Kaggle-v0.11.csv', low_memory=False)\n",
    "\n",
    "# get indexes for predictions\n",
    "indexes = df_raw_kaggle[\"Unnamed: 0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../data/immo_data_clean.csv', low_memory=False)\n",
    "df_kaggle = pd.read_csv('../../../data/test_data_kaggle_clean.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\n",
    "\t\"Zip\",\n",
    "\t\"Availability_Categorized\",\n",
    "\n",
    "\t\"Floor_unified\", \n",
    "    \"gde_politics_bdp\",\n",
    "    \"gde_politics_cvp\",\n",
    "    \"gde_politics_evp\",\n",
    "    \"gde_politics_fdp\",\n",
    "    \"gde_politics_glp\",\n",
    "    \"gde_politics_gps\",\n",
    "    \"gde_politics_pda\",\n",
    "    \"gde_politics_rights\",\n",
    "    \"gde_politics_sp\",\n",
    "    \"gde_politics_svp\",\n",
    "\n",
    "    \"NoisePollutionRailwayL\", \"NoisePollutionRailwayM\", \"NoisePollutionRailwayS\", \n",
    "    \"NoisePollutionRoadL\", \"NoisePollutionRoadM\", \"NoisePollutionRoadS\", \n",
    "    \"PopulationDensityL\", \"PopulationDensityM\", \"PopulationDensityS\", \n",
    "    \"RiversAndLakesL\", \"RiversAndLakesM\", \"RiversAndLakesS\", \n",
    "    \"WorkplaceDensityL\", \"WorkplaceDensityM\", \"WorkplaceDensityS\", \n",
    "    \"ForestDensityL\", \"ForestDensityM\", \"ForestDensityS\"\n",
    "])\n",
    "df_kaggle = df_kaggle.drop(columns=[\n",
    "\t\"Zip\",\n",
    "\t\"Availability_Categorized\",\n",
    "\n",
    "\t\"Floor_unified\", \n",
    "    \"gde_politics_bdp\",\n",
    "    \"gde_politics_cvp\",\n",
    "    \"gde_politics_evp\",\n",
    "    \"gde_politics_fdp\",\n",
    "    \"gde_politics_glp\",\n",
    "    \"gde_politics_gps\",\n",
    "    \"gde_politics_pda\",\n",
    "    \"gde_politics_rights\",\n",
    "    \"gde_politics_sp\",\n",
    "    \"gde_politics_svp\",\n",
    "\n",
    "    \"NoisePollutionRailwayL\", \"NoisePollutionRailwayM\", \"NoisePollutionRailwayS\", \n",
    "    \"NoisePollutionRoadL\", \"NoisePollutionRoadM\", \"NoisePollutionRoadS\", \n",
    "    \"PopulationDensityL\", \"PopulationDensityM\", \"PopulationDensityS\", \n",
    "    \"RiversAndLakesL\", \"RiversAndLakesM\", \"RiversAndLakesS\", \n",
    "    \"WorkplaceDensityL\", \"WorkplaceDensityM\", \"WorkplaceDensityS\", \n",
    "    \"ForestDensityL\", \"ForestDensityM\", \"ForestDensityS\"\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after removing rows with missing target values:\n",
      "(21444, 64)\n",
      "Kaggle Test Dataset\n",
      "(24556, 64)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_dataframe(df):\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    df_processed = pd.get_dummies(df, columns=categorical_columns, drop_first=True, dtype=int)\n",
    "\n",
    "    return df_processed, numerical_columns\n",
    "\n",
    "\n",
    "def remove_outliers(df, numerical_columns):\n",
    "    df_processed = df.copy()\n",
    "\n",
    "    quantiles_1 = df_processed[numerical_columns].quantile(0)\n",
    "    quantiles_99 = df_processed[numerical_columns].quantile(0.99)\n",
    "\n",
    "    for column in numerical_columns:\n",
    "        condition = (df_processed[column] < quantiles_1[column]) | (df_processed[column] > quantiles_99[column])\n",
    "        df_processed.loc[condition, column] = None\n",
    "\n",
    "    return df_processed\n",
    "\n",
    "df, num_cols_df = preprocess_dataframe(df)\n",
    "df_kaggle, num_cols_df_kaggle = preprocess_dataframe(df_kaggle)\n",
    "\n",
    "#df = remove_outliers(df, num_cols_df)\n",
    "\n",
    "df = df[df['price_cleaned'] > 10000]\n",
    "\n",
    "df = df.dropna(subset=['price_cleaned'], axis=0)\n",
    "\n",
    "print(\"Dataset after removing rows with missing target values:\")\n",
    "print(df.shape)\n",
    "\n",
    "print(\"Kaggle Test Dataset\")\n",
    "print(df_kaggle.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price_cleaned                     float64\n",
       "Year built:                       float64\n",
       "Living_area_unified               float64\n",
       "Floor_space_merged                float64\n",
       "Plot_area_unified                 float64\n",
       "                                   ...   \n",
       "type_unified_stepped-apartment      int32\n",
       "type_unified_stepped-house          int32\n",
       "type_unified_studio                 int32\n",
       "type_unified_terrace-house          int32\n",
       "type_unified_villa                  int32\n",
       "Length: 64, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframes do not have the same column names.\n",
      "Columns in df1 not in df2: {'price_cleaned'}\n",
      "Columns in df2 not in df1 (dropped): {'type_unified_furnished-residential-property'}\n"
     ]
    }
   ],
   "source": [
    "columns_df1 = set(df.columns)\n",
    "columns_df2 = set(df_kaggle.columns)\n",
    "\n",
    "# Compare the sets of columns\n",
    "if columns_df1 == columns_df2:\n",
    "    print(\"The dataframes have the same column names.\")\n",
    "else:\n",
    "    print(\"The dataframes do not have the same column names.\")\n",
    "\n",
    "    # Find out which columns are different\n",
    "    diff_df1 = columns_df1 - columns_df2\n",
    "    diff_df2 = columns_df2 - columns_df1\n",
    "\n",
    "    if diff_df1:\n",
    "        print(\"Columns in df1 not in df2:\", diff_df1)\n",
    "    if diff_df2:\n",
    "        print(\"Columns in df2 not in df1 (dropped):\", diff_df2)\n",
    "        df_kaggle.drop(diff_df2, axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (17155, 63)\n",
      "y_train shape:  (17155,)\n",
      "X_test shape:  (4289, 63)\n",
      "y_test shape:  (4289,)\n",
      "X_test_kaggle shape:  (24556, 63)\n"
     ]
    }
   ],
   "source": [
    "train, val = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = train.drop(\"price_cleaned\", axis=1)\n",
    "y_train = train[\"price_cleaned\"]\n",
    "\n",
    "X_val= val.drop(\"price_cleaned\", axis=1)\n",
    "y_val = val[\"price_cleaned\"]\n",
    "\n",
    "X_test_kaggle = df_kaggle\n",
    "\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"X_test shape: \", X_val.shape)\n",
    "print(\"y_test shape: \", y_val.shape)\n",
    "print(\"X_test_kaggle shape: \", X_test_kaggle.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X_train.columns\n",
    "\n",
    "X_train_with_na = X_train.copy()\n",
    "X_val_with_na = X_val.copy()\n",
    "X_test_kaggle_with_na = X_test_kaggle.copy()\n",
    "X_test_kaggle_with_na = X_test_kaggle_with_na[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=cols)\n",
    "X_val_imputed = pd.DataFrame(imputer.transform(X_val), columns=cols)\n",
    "X_test_kaggle_imputed = pd.DataFrame(imputer.fit_transform(df_kaggle), columns=cols)\n",
    "\n",
    "# export imputed train and test data to csv so we dont always have to run the imputation\n",
    "X_train_imputed.to_csv('../../../data/X_train_imputed.csv')\n",
    "X_val_imputed.to_csv('../../../data/X_test_imputed.csv')\n",
    "X_test_kaggle_imputed.to_csv('../../../data/X_test_kaggle_imputed.csv')\n",
    "\n",
    "y_train.to_csv('../../../data/y_train.csv')\n",
    "y_val.to_csv('../../../data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (17155, 63)\n",
      "y_train shape:  (17155,)\n"
     ]
    }
   ],
   "source": [
    "X_train_imputed = pd.read_csv('../../../data/X_train_imputed.csv', low_memory=False)\n",
    "X_val_imputed = pd.read_csv('../../../data/X_test_imputed.csv', low_memory=False)\n",
    "X_test_kaggle_imputed = pd.read_csv('../../../data/X_test_kaggle_imputed.csv', low_memory=False)\n",
    "y_train = pd.read_csv('../../../data/y_train.csv', low_memory=False)\n",
    "y_val = pd.read_csv('../../../data/y_test.csv', low_memory=False)\n",
    "\n",
    "# ignore first column of X_train\n",
    "X_train = X_train_imputed.iloc[:, 1:]\n",
    "\n",
    "# # ignore first column of X_test\n",
    "X_val = X_val_imputed.iloc[:, 1:]\n",
    "\n",
    "# # ignore first column of X_test_kaggle\n",
    "X_test_kaggle = X_test_kaggle_imputed.iloc[:, 1:]\n",
    "\n",
    "# # ignore first column of y_train\n",
    "y_train = y_train.iloc[:, 1:].values.ravel()\n",
    "\n",
    "# # ignore first column of y_test\n",
    "y_val = y_val.iloc[:, 1:].values.ravel()\n",
    "\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "# print(\"X_test shape: \", X_test.shape)\n",
    "# print(\"y_test shape: \", y_test.shape)\n",
    "# print(\"X_test_kaggle shape: \", X_test_kaggle.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscaler = StandardScaler()\\n\\n# fit scaler on training data\\nscaler = scaler.fit(X_train_with_na)\\n\\nX_train_with_na = pd.DataFrame(scaler.transform(X_train_with_na), columns=cols)\\nX_val_with_na = pd.DataFrame(scaler.transform(X_val_with_na), columns=cols)\\nX_test_kaggle_with_na = pd.DataFrame(scaler.transform(X_test_kaggle_with_na), columns=cols)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit scaler on training data\n",
    "scaler = scaler.fit(X_train_with_na)\n",
    "\n",
    "X_train_with_na = pd.DataFrame(scaler.transform(X_train_with_na), columns=cols)\n",
    "X_val_with_na = pd.DataFrame(scaler.transform(X_val_with_na), columns=cols)\n",
    "X_test_kaggle_with_na = pd.DataFrame(scaler.transform(X_test_kaggle_with_na), columns=cols)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler = scaler.fit(X_train)\n",
    "X_train = pd.DataFrame(scaler.transform(X_train), columns=cols)\n",
    "X_val = pd.DataFrame(scaler.transform(X_val), columns=cols)\n",
    "X_test_kaggle = pd.DataFrame(scaler.transform(X_test_kaggle), columns=cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell 4: XGBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Dokumentation](https://xgboost.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'booster': 'gbtree', 'learning_rate': 0.2, 'max_depth': 9, 'random_state': 42}\n",
      "MAPE: 0.2903\n",
      "R2: 0.7473\n"
     ]
    }
   ],
   "source": [
    "def xgb_model(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        X_test, \n",
    "        y_test, \n",
    "        cv,\n",
    "        max_depth,\n",
    "        learning_rate,\n",
    "        booster\n",
    "    ):\n",
    "    \n",
    "    xgb = XGBRegressor()\n",
    "\n",
    "    param_grid = {\n",
    "        'max_depth': max_depth,\n",
    "        'learning_rate': learning_rate,\n",
    "        'booster': booster,\n",
    "        'random_state': [42]\n",
    "    }\n",
    "\n",
    "    grid_xgb = GridSearchCV(xgb, param_grid, cv=cv, n_jobs=-1, scoring='neg_mean_absolute_percentage_error', verbose=1)\n",
    "\n",
    "    grid_xgb.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_xgb.best_params_\n",
    "    print('Best parameters: {}'.format(best_params))\n",
    "\n",
    "    y_pred_xgb = grid_xgb.predict(X_test)\n",
    "\n",
    "    mape_xgb = round(mean_absolute_percentage_error(y_test, y_pred_xgb), 4)\n",
    "    print('MAPE: {}'.format(mape_xgb))\n",
    "\n",
    "    r2_xgb = round(r2_score(y_test, y_pred_xgb), 4)\n",
    "    print('R2: {}'.format(r2_xgb))\n",
    "\n",
    "    return grid_xgb, mape_xgb\n",
    "\n",
    "xgb_regression, mape_xgb = xgb_model(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    cv=5,\n",
    "    max_depth = [None, 6, 9, 12, 15],\n",
    "    learning_rate = [0.01, 0.1, 0.2],\n",
    "    booster = ['gbtree']\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell 5: XGBoost (Log-Transformiert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 12, 'random_state': 42}\n",
      "MAPE: 0.2427\n",
      "R2: 0.7243\n"
     ]
    }
   ],
   "source": [
    "def xgb_model(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        cv,\n",
    "        max_depth,\n",
    "        learning_rate,\n",
    "        booster\n",
    "    ):\n",
    "\n",
    "    xgb = XGBRegressor()\n",
    "\n",
    "    param_grid = {\n",
    "        'max_depth': max_depth,\n",
    "        'learning_rate': learning_rate,\n",
    "        'booster': booster,\n",
    "        'random_state': [42]\n",
    "    }\n",
    "\n",
    "    grid_xgb = GridSearchCV(xgb, param_grid, cv=cv, n_jobs=-1, scoring='neg_mean_absolute_percentage_error', verbose=1)\n",
    "\n",
    "    grid_xgb.fit(X_train, np.log(y_train))\n",
    "\n",
    "    best_params = grid_xgb.best_params_\n",
    "    print('Best parameters: {}'.format(best_params))\n",
    "\n",
    "    y_pred_xgb = grid_xgb.predict(X_test)\n",
    "    y_pred_xgb = np.exp(y_pred_xgb)\n",
    "\n",
    "    mape_xgb = round(mean_absolute_percentage_error(y_test, y_pred_xgb), 4)\n",
    "    print('MAPE: {}'.format(mape_xgb))\n",
    "\n",
    "    r2_xgb = round(r2_score(y_test, y_pred_xgb), 4)\n",
    "    print('R2: {}'.format(r2_xgb))\n",
    "\n",
    "    return grid_xgb, mape_xgb\n",
    "\n",
    "xgb_regression_log, mape_xgb_log = xgb_model(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    cv=5,\n",
    "    max_depth = [None, 6, 9, 12],\n",
    "    learning_rate = [0.01, 0.1, 0.3],\n",
    "    booster = ['gbtree']\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell 6: Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Dokumentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best parameters: {'random_state': 42}\n",
      "MAPE: 0.3463\n",
      "R2: 0.7563\n"
     ]
    }
   ],
   "source": [
    "def rf_model(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        X_test, \n",
    "        y_test, \n",
    "        cv\n",
    "    ):\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "\n",
    "    param_grid = {\n",
    "        'random_state': [42]\n",
    "    }\n",
    "\n",
    "    grid_rf = GridSearchCV(rf, param_grid, cv=cv, n_jobs=-1, scoring='neg_mean_absolute_percentage_error', verbose=1)\n",
    "\n",
    "    grid_rf.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_rf.best_params_\n",
    "    print('Best parameters: {}'.format(best_params))\n",
    "\n",
    "    y_pred_rf = grid_rf.predict(X_test)\n",
    "\n",
    "    mape_rf = round(mean_absolute_percentage_error(y_test, y_pred_rf), 4)\n",
    "    print('MAPE: {}'.format(mape_rf))\n",
    "\n",
    "    r2_rf = round(r2_score(y_test, y_pred_rf), 4)\n",
    "    print('R2: {}'.format(r2_rf))\n",
    "\n",
    "    return grid_rf, mape_rf\n",
    "\n",
    "rf_regression, mape_rf = rf_model(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell 7: Random Forest (Log-Transformiert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'random_state': 42}\n",
      "MAPE: 0.2536\n",
      "R2: 0.7378\n"
     ]
    }
   ],
   "source": [
    "def rf_model(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        cv,\n",
    "    ):\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "\n",
    "    param_grid = {\n",
    "        'random_state': [42],\n",
    "    }\n",
    "\n",
    "    grid_rf = GridSearchCV(rf, param_grid, cv=cv, n_jobs=-1, scoring='neg_mean_absolute_percentage_error', verbose=1)\n",
    "\n",
    "    grid_rf.fit(X_train, np.log(y_train))\n",
    "\n",
    "    best_params = grid_rf.best_params_\n",
    "    print('Best parameters: {}'.format(best_params))\n",
    "\n",
    "    y_pred_rf = grid_rf.predict(X_test)\n",
    "    y_pred_rf = np.exp(y_pred_rf)\n",
    "\n",
    "    mape_rf = round(mean_absolute_percentage_error(y_test, y_pred_rf), 4)\n",
    "    print('MAPE: {}'.format(mape_rf))\n",
    "\n",
    "    r2_rf = round(r2_score(y_test, y_pred_rf), 4)\n",
    "    print('R2: {}'.format(r2_rf))\n",
    "\n",
    "    return grid_rf, mape_rf\n",
    "\n",
    "rf_regression_log, mape_rf_log = rf_model(\n",
    "     X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell 8: Hist Gradient Boosting Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Dokumentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'l2_regularization': 0.1, 'learning_rate': 0.1, 'loss': 'gamma', 'max_depth': None, 'max_iter': 300, 'max_leaf_nodes': 70, 'random_state': 27}\n",
      "MAPE: 0.2711\n",
      "R2: 0.7359\n"
     ]
    }
   ],
   "source": [
    "def hgb_model(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        X_test, \n",
    "        y_test, \n",
    "        cv, \n",
    "        loss,\n",
    "        learning_rate, \n",
    "        max_iter,\n",
    "        max_leaf_nodes,\n",
    "        max_depth, \n",
    "        l2_regularization, \n",
    "        random_state,\n",
    "    ):\n",
    "    \n",
    "    hgb = HistGradientBoostingRegressor()\n",
    "\n",
    "    param_grid = {\n",
    "        'loss': loss,\n",
    "        'learning_rate': learning_rate,\n",
    "        'max_iter': max_iter,\n",
    "        'max_leaf_nodes': max_leaf_nodes,\n",
    "        'max_depth': max_depth,\n",
    "        'l2_regularization': l2_regularization,\n",
    "        'random_state': random_state\n",
    "    }\n",
    "\n",
    "    grid_hgb = GridSearchCV(hgb, param_grid, cv=cv, n_jobs=-1, scoring='neg_mean_absolute_percentage_error', verbose=1)\n",
    "\n",
    "    grid_hgb.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_hgb.best_params_\n",
    "    print('Best parameters: {}'.format(best_params))\n",
    "\n",
    "    y_pred_hgb = grid_hgb.predict(X_test)\n",
    "\n",
    "    mape_hgb = round(mean_absolute_percentage_error(y_test, y_pred_hgb), 4)\n",
    "    print('MAPE: {}'.format(mape_hgb))\n",
    "\n",
    "    r2_hgb = round(r2_score(y_test, y_pred_hgb), 4)\n",
    "    print('R2: {}'.format(r2_hgb))\n",
    "\n",
    "    return grid_hgb, mape_hgb\n",
    "\n",
    "hgb_regression, mape_hgb = hgb_model(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    cv=5,\n",
    "    loss = ['gamma'],\n",
    "    learning_rate = [0.1],\n",
    "    max_iter = [300],\n",
    "    max_leaf_nodes = [70],\n",
    "    max_depth = [None],\n",
    "    l2_regularization = [0.1],\n",
    "    random_state = [27]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell 9: Hist Gradient Boosting Regression (Log-Transformiert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best parameters: {'l2_regularization': 0.1, 'learning_rate': 0.01, 'loss': 'gamma', 'max_depth': None, 'max_iter': 3500, 'max_leaf_nodes': 26, 'random_state': 42}\n",
      "MAPE: 0.2893\n",
      "MAPE: 0.2191\n",
      "R2: 0.7156\n"
     ]
    }
   ],
   "source": [
    "def hgb_model(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        X_test, \n",
    "        y_test, \n",
    "        cv, \n",
    "        loss,\n",
    "        learning_rate, \n",
    "        max_iter,\n",
    "        max_leaf_nodes,\n",
    "        max_depth, \n",
    "        l2_regularization, \n",
    "        random_state,\n",
    "    ):\n",
    "    \n",
    "    hgb = HistGradientBoostingRegressor()\n",
    "\n",
    "    param_grid = {\n",
    "        'loss': loss,\n",
    "        'learning_rate': learning_rate,\n",
    "        'max_iter': max_iter,\n",
    "        'max_leaf_nodes': max_leaf_nodes,\n",
    "        'max_depth': max_depth,\n",
    "        'l2_regularization': l2_regularization,\n",
    "        'random_state': random_state\n",
    "    }\n",
    "\n",
    "    grid_hgb = GridSearchCV(hgb, param_grid, cv=cv, n_jobs=-1, scoring='neg_mean_absolute_percentage_error', verbose=1)\n",
    "\n",
    "    grid_hgb.fit(X_train, np.log(y_train))\n",
    "\n",
    "    best_params = grid_hgb.best_params_\n",
    "    print('Best parameters: {}'.format(best_params))\n",
    "\n",
    "    y_pred_hgb = grid_hgb.predict(X_test)\n",
    "    y_pred_hgb = np.exp(y_pred_hgb)\n",
    "    y_pred_hgb2 = grid_hgb.predict(X_train)\n",
    "    y_pred_hgb2 = np.exp(y_pred_hgb2)\n",
    "\n",
    "    mape_hgb = round(mean_absolute_percentage_error(y_test, y_pred_hgb), 4)\n",
    "    print('MAPE: {}'.format(mape_hgb))\n",
    "    mape_hgb2 = round(mean_absolute_percentage_error(y_train, y_pred_hgb2), 4)\n",
    "    print('MAPE: {}'.format(mape_hgb2))\n",
    "\n",
    "    r2_hgb = round(r2_score(y_test, y_pred_hgb), 4)\n",
    "    print('R2: {}'.format(r2_hgb))\n",
    "\n",
    "    return grid_hgb, mape_hgb\n",
    "\n",
    "hgb_regression_log, mape_hgb_log = hgb_model(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    cv=5,\n",
    "    loss = ['gamma'],\n",
    "    learning_rate = [0.01],\n",
    "    max_iter = [3500],\n",
    "    max_leaf_nodes = [26],\n",
    "    max_depth = [None],\n",
    "    l2_regularization = [0.1],\n",
    "    random_state = [42]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train and val together and then predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\laeub\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but HistGradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# train hgb_regression_log again with best parameters with X_train_with_na and X_val_with_na\n",
    "best_params = {\n",
    "    'l2_regularization': 0.2,\n",
    "    'learning_rate': 0.1,\n",
    "    'loss': 'gamma',\n",
    "    'max_depth': None,\n",
    "    'max_iter': 200,\n",
    "    'max_leaf_nodes': 100,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Initialize the HistGradientBoostingRegressor with best parameters\n",
    "hgb_best = HistGradientBoostingRegressor(**best_params)\n",
    "\n",
    "# Combining the training and validation sets\n",
    "X_train_combined = np.vstack((X_train, X_val))\n",
    "y_train_combined = np.hstack((y_train, y_val))\n",
    "\n",
    "# Training the model on the combined dataset\n",
    "hgb_best.fit(X_train_combined, np.log(y_train_combined))\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred_hgb_best = hgb_best.predict(X_test_kaggle)\n",
    "y_pred_hgb_best = np.exp(y_pred_hgb_best)\n",
    "\n",
    "predictions = pd.DataFrame({\"ID\": indexes, \"Expected\": y_pred_hgb_best})\n",
    "predictions.to_csv('../../99_gespeicherte_modelle/predictions_hgb_log.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell 10: Gradient Boosting Regression\n",
    "\n",
    "[Dokumentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.1, 'max_depth': 9, 'random_state': 42}\n",
      "MAPE: 0.2927\n",
      "R2: 0.7541\n"
     ]
    }
   ],
   "source": [
    "def gb_model(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        cv,\n",
    "        max_depth,\n",
    "        learning_rate,\n",
    "    ):\n",
    "\n",
    "    gb = GradientBoostingRegressor()\n",
    "\n",
    "    param_grid = {\n",
    "        'max_depth': max_depth,\n",
    "        'learning_rate': learning_rate,\n",
    "        'random_state': [42]\n",
    "    }\n",
    "\n",
    "    grid_gb = GridSearchCV(gb, param_grid, cv=cv, n_jobs=-1, scoring='neg_mean_absolute_percentage_error', verbose=1)\n",
    "\n",
    "    grid_gb.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_gb.best_params_\n",
    "    print('Best parameters: {}'.format(best_params))\n",
    "\n",
    "    y_pred_gb = grid_gb.predict(X_test)\n",
    "\n",
    "    mape_gb = round(mean_absolute_percentage_error(y_test, y_pred_gb), 4)\n",
    "    print('MAPE: {}'.format(mape_gb))\n",
    "\n",
    "    r2_gb = round(r2_score(y_test, y_pred_gb), 4)\n",
    "    print('R2: {}'.format(r2_gb))\n",
    "\n",
    "    return grid_gb, mape_gb\n",
    "\n",
    "gb_regression, mape_gb = gb_model(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    cv=5,\n",
    "    max_depth = [None, 3, 6, 9],\n",
    "    learning_rate = [0.01, 0.1],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell 11: Gradient Boosting Regression (Log-Transformiert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best parameters: {'learning_rate': 0.1, 'max_depth': 9, 'random_state': 42}\n",
      "MAPE: 0.2463\n",
      "R2: 0.728\n"
     ]
    }
   ],
   "source": [
    "def gb_model(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        cv,\n",
    "        max_depth,\n",
    "        learning_rate\n",
    "    ):\n",
    "\n",
    "    gb = GradientBoostingRegressor()\n",
    "\n",
    "    param_grid = {\n",
    "        'max_depth': max_depth,\n",
    "        'learning_rate': learning_rate,\n",
    "        'random_state': [42]\n",
    "    }\n",
    "\n",
    "    grid_gb = GridSearchCV(gb, param_grid, cv=cv, n_jobs=-1, scoring='neg_mean_absolute_percentage_error', verbose=1)\n",
    "\n",
    "    grid_gb.fit(X_train, np.log(y_train))\n",
    "\n",
    "    best_params = grid_gb.best_params_\n",
    "    print('Best parameters: {}'.format(best_params))\n",
    "\n",
    "    y_pred_gb = grid_gb.predict(X_test)\n",
    "    y_pred_gb = np.exp(y_pred_gb)\n",
    "\n",
    "    mape_gb = round(mean_absolute_percentage_error(y_test, y_pred_gb), 4)\n",
    "    print('MAPE: {}'.format(mape_gb))\n",
    "\n",
    "    r2_gb = round(r2_score(y_test, y_pred_gb), 4)\n",
    "    print('R2: {}'.format(r2_gb))\n",
    "\n",
    "    return grid_gb, mape_gb\n",
    "\n",
    "gb_regression_log, mape_gb_log = gb_model(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    cv=5,\n",
    "    max_depth = [None, 3, 6, 9],\n",
    "    learning_rate = [0.01, 0.1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Making predictions on the test set\n",
    "y_pred_hgb_best = hgb_regression_log.predict(X_test_kaggle)\n",
    "y_pred_hgb_best = np.exp(y_pred_hgb_best)\n",
    "\n",
    "predictions = pd.DataFrame({\"ID\": indexes, \"Expected\": y_pred_hgb_best})\n",
    "predictions.to_csv('../../99_gespeicherte_modelle/predictions_hgb_regression_log.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Datensatz Predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions Visualisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69341.2512072161\n",
      "20341724.946851578\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_pred_hgb_best.min())\n",
    "print(y_pred_hgb_best.max())\n",
    "\n",
    "sns.histplot(y_pred_hgb_best)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions from Best Model yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../data/predictions_best.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pred_best \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../../data/predictions_best.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m pred_best \u001b[38;5;241m=\u001b[39m pred_best[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      5\u001b[0m sns\u001b[38;5;241m.\u001b[39mhistplot(pred_best)\n",
      "File \u001b[1;32mc:\\Users\\laeub\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\laeub\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\laeub\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\laeub\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\laeub\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../data/predictions_best.csv'"
     ]
    }
   ],
   "source": [
    "pred_best = pd.read_csv('../../../data/predictions_best.csv')\n",
    "\n",
    "pred_best = pred_best[\"Expected\"]\n",
    "\n",
    "sns.histplot(pred_best)\n",
    "plt.show()\n",
    "\n",
    "print(pred_best.min())\n",
    "print(pred_best.max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd9c78cbb62892232a2e8cf9a4bd699d988202e949c50bb9be5232199c394801"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
